{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "from six.moves import cPickle as pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the small data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pickle_file = 'mini_train.pickle'\n",
    "pickle_file = 'train.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    mini_X_0 = save['data']\n",
    "    mini_outcome = save['outcome']\n",
    "    del save  # hint to help gc free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reformat the label\n",
    "#for each digit, add a 'end_digit' as '10'\n",
    "#for each label, add a digit size\n",
    "#each of them is a one-hot coding\n",
    "\n",
    "def label_reformat(label, max_size = 5):\n",
    "    digit_size = np.asarray([len(x) for x in label])\n",
    "    digit_size[digit_size > max_size]= max_size\n",
    "    digit_size = ((np.arange(max_size)+1) == digit_size[:,None]).astype(np.float32)\n",
    "    \n",
    "    digits = {}\n",
    "    end_digit = 10.0\n",
    "    for i in range(max_size):\n",
    "        digit_coding = np.asarray( [x[i] if len(x)>i else end_digit for x in label])\n",
    "        digit_coding = (np.arange(end_digit+1) == digit_coding[:,None]).astype(np.float32)\n",
    "        digits['digit_'+ str(i)] = digit_coding\n",
    "        \n",
    "    return digit_size, digits   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sample a smaller data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label = mini_outcome['label'][:100]\n",
    "digit_size, digits = label_reformat(label)\n",
    "mini_X = mini_X_0[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5)\n",
      "(100, 11)\n",
      "(100, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print digit_size.shape\n",
    "print digits['digit_0'].shape\n",
    "print mini_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start tensorflow session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "image_size = mini_X.shape[1]\n",
    "num_channels = mini_X.shape[3]\n",
    "batch_size = 20\n",
    "\n",
    "x_image = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "\n",
    "y_d1 = tf.placeholder(tf.float32, shape=(batch_size, 11))\n",
    "y_d2 = tf.placeholder(tf.float32, shape=(batch_size, 11))\n",
    "y_d3 = tf.placeholder(tf.float32, shape=(batch_size, 11))\n",
    "y_d4 = tf.placeholder(tf.float32, shape=(batch_size, 11))\n",
    "y_d5 = tf.placeholder(tf.float32, shape=(batch_size, 11))\n",
    "\n",
    "y_dsize = tf.placeholder(tf.float32, shape=(batch_size, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_batch(X, y_dsize, y_ds, batch_size=50):\n",
    "    idx = np.random.choice(X.shape[0],batch_size)\n",
    "    batch_x = X[idx,:,:,:]\n",
    "    batch_y_dsize = y_dsize[idx,:]\n",
    "    batch_y_d1 = y_ds['digit_0'][idx,:]\n",
    "    batch_y_d2 = y_ds['digit_1'][idx,:]\n",
    "    batch_y_d3 = y_ds['digit_2'][idx,:]\n",
    "    batch_y_d4 = y_ds['digit_3'][idx,:]\n",
    "    batch_y_d5 = y_ds['digit_4'][idx,:]\n",
    "    \n",
    "    return batch_x, batch_y_dsize, batch_y_d1, batch_y_d2, batch_y_d3, batch_y_d4, batch_y_d5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, num_channels, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([16 * 16 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 16*16*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop out layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully connected layers\n",
    "several different softmax header, for different digits and digit size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#first digit\n",
    "W_fc2_d1 = weight_variable([1024, 11])\n",
    "b_fc2_d1 = bias_variable([11])\n",
    "\n",
    "y_conv_d1 = tf.matmul(h_fc1_drop, W_fc2_d1) + b_fc2_d1\n",
    "\n",
    "#second digit\n",
    "W_fc2_d2 = weight_variable([1024, 11])\n",
    "b_fc2_d2 = bias_variable([11])\n",
    "\n",
    "y_conv_d2 = tf.matmul(h_fc1_drop, W_fc2_d2) + b_fc2_d2\n",
    "\n",
    "#third digit\n",
    "W_fc2_d3 = weight_variable([1024, 11])\n",
    "b_fc2_d3 = bias_variable([11])\n",
    "\n",
    "y_conv_d3 = tf.matmul(h_fc1_drop, W_fc2_d3) + b_fc2_d3\n",
    "\n",
    "#fourth digit\n",
    "W_fc2_d4 = weight_variable([1024, 11])\n",
    "b_fc2_d4 = bias_variable([11])\n",
    "\n",
    "y_conv_d4 = tf.matmul(h_fc1_drop, W_fc2_d4) + b_fc2_d4\n",
    "\n",
    "#fifth digit\n",
    "W_fc2_d5 = weight_variable([1024, 11])\n",
    "b_fc2_d5 = bias_variable([11])\n",
    "\n",
    "y_conv_d5 = tf.matmul(h_fc1_drop, W_fc2_d5) + b_fc2_d5\n",
    "\n",
    "#digit size\n",
    "W_fc2_dsize = weight_variable([1024, 5])\n",
    "b_fc2_dsize = bias_variable([5])\n",
    "\n",
    "y_conv_dsize = tf.matmul(h_fc1_drop, W_fc2_dsize) + b_fc2_dsize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_entropy = ( tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_conv_d1, y_d1)) \n",
    "                 + tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_conv_d2, y_d2))\n",
    "                 + tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_conv_d3, y_d3))\n",
    "                 + tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_conv_d4, y_d4))\n",
    "                 + tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_conv_d5, y_d5))\n",
    "                 + tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_conv_dsize, y_dsize))\n",
    "                 )\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#let's just check the first digit\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv_d1,1), tf.argmax(y_d1,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model on a small data, see whether it overfit \n",
    "if overfit, then good. If not, check bugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.05\n",
      "step 10, training accuracy 0.3\n",
      "step 20, training accuracy 0.3\n",
      "step 30, training accuracy 0.3\n",
      "step 40, training accuracy 0.25\n",
      "step 50, training accuracy 0.45\n",
      "step 60, training accuracy 0.3\n",
      "step 70, training accuracy 0.2\n",
      "step 80, training accuracy 0.45\n",
      "step 90, training accuracy 0.45\n",
      "step 100, training accuracy 0.45\n",
      "step 110, training accuracy 0.6\n",
      "step 120, training accuracy 0.5\n",
      "step 130, training accuracy 0.8\n",
      "step 140, training accuracy 0.6\n",
      "step 150, training accuracy 0.85\n",
      "step 160, training accuracy 0.75\n",
      "step 170, training accuracy 0.7\n",
      "step 180, training accuracy 0.9\n",
      "step 190, training accuracy 0.75\n",
      "step 200, training accuracy 1\n",
      "step 210, training accuracy 0.75\n",
      "step 220, training accuracy 1\n",
      "step 230, training accuracy 0.75\n",
      "step 240, training accuracy 0.9\n",
      "step 250, training accuracy 0.9\n",
      "step 260, training accuracy 0.9\n",
      "step 270, training accuracy 0.9\n",
      "step 280, training accuracy 0.95\n",
      "step 290, training accuracy 1\n",
      "step 300, training accuracy 0.95\n",
      "step 310, training accuracy 1\n",
      "step 320, training accuracy 0.95\n",
      "step 330, training accuracy 1\n",
      "step 340, training accuracy 0.95\n",
      "step 350, training accuracy 1\n",
      "step 360, training accuracy 1\n",
      "step 370, training accuracy 1\n",
      "step 380, training accuracy 1\n",
      "step 390, training accuracy 1\n",
      "step 400, training accuracy 1\n",
      "step 410, training accuracy 1\n",
      "step 420, training accuracy 1\n",
      "step 430, training accuracy 1\n",
      "step 440, training accuracy 1\n",
      "step 450, training accuracy 1\n",
      "step 460, training accuracy 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-e1195155f09e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0my_d1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y_d1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_d2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y_d2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_d3\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y_d3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0my_d4\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y_d4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_d5\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y_d5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             keep_prob: 0.5})\n\u001b[0m",
      "\u001b[0;32m/home/josh/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   1617\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1618\u001b[0m     \"\"\"\n\u001b[0;32m-> 1619\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/josh/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3794\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3795\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3796\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/josh/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/josh/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/josh/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/josh/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/josh/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "sess.run(tf.initialize_all_variables())\n",
    "for i in range(1000):\n",
    "    batch_x, batch_y_dsize, batch_y_d1, batch_y_d2, batch_y_d3, batch_y_d4, batch_y_d5 = next_batch(mini_X, digit_size, digits, batch_size)\n",
    "    if i%10 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "                x_image: batch_x, y_dsize: batch_y_dsize,\n",
    "                y_d1: batch_y_d1, y_d2: batch_y_d2, y_d3: batch_y_d3,\n",
    "                y_d4: batch_y_d4, y_d5: batch_y_d5,\n",
    "                keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_step.run(feed_dict={\n",
    "            x_image: batch_x, y_dsize: batch_y_dsize,\n",
    "            y_d1: batch_y_d1, y_d2: batch_y_d2, y_d3: batch_y_d3,\n",
    "            y_d4: batch_y_d4, y_d5: batch_y_d5,\n",
    "            keep_prob: 0.5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
